# SIREN: Multi-Objective Game-Theoretic Scheduler based on Memory-Driven Grey Wolf Optimization in Fog-Cloud Computing

This repository contains the complete implementation of **SIREN**, a Swarm-Intelligence-driven, game-theoretic framework for fault-tolerant, energy-efficient task scheduling in fog-cloud computing environments.

## Overview

SIREN combines:
1. **Game-Theoretic Modeling**: Treats fog nodes as strategic players, each optimizing a payoff function balancing reliability and energy
2. **Memory-Driven Grey Wolf Optimization (MD-GWO)**: A meta-heuristic solver that maintains a memory archive for convergence stability
3. **Multi-Objective Optimization**: Jointly minimizes energy consumption while maximizing task-success probability (reliability)
4. **Dynamic Adaptation**: Continuously monitors system state and re-optimizes upon task arrivals or failures

## Key Achievements (from Paper)

- **100% task success rate** on healthcare scenarios (critical tasks fully replicated)
- **2.08Ã— â€“ 4.24Ã— lower energy** consumption than leading baselines (Alibaba & Google traces)
- **3.9Ã— â€“ 5.8Ã— reduction** in network usage on average
- **Stable performance** even at 20% node fault rates

## Project Structure

```
siren-fog-gwo/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ LICENSE                            # Apache 2.0
â”œâ”€â”€ setup.py                           # Python package setup
â”œâ”€â”€ requirements.txt                   # Pinned dependencies
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ topology.yaml                  # Fog-cloud network topology
â”‚   â”œâ”€â”€ workload.yaml                  # Task/application parameters
â”‚   â”œâ”€â”€ algorithm.yaml                 # MD-GWO hyperparameters
â”‚   â””â”€â”€ evaluation.yaml                # Metric and baseline configs
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ASSUMPTIONS.md                 # Design assumptions & engineering choices
â”‚   â”œâ”€â”€ REPRODUCIBILITY.md             # Step-by-step reproduction guide
â”‚   â””â”€â”€ API.md                         # Module/class API reference
â”‚
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ fog_gwo_scheduler/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ system_model.py        # FogCloud topology, task, network models
â”‚   â”‚   â”‚   â”œâ”€â”€ objectives.py          # Energy & reliability objectives
â”‚   â”‚   â”‚   â””â”€â”€ constraints.py         # Resource/deadline constraints + penalty
â”‚   â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ mdgwo.py               # Memory-Driven GWO implementation
â”‚   â”‚   â”‚   â””â”€â”€ game_theory.py         # Nash equilibrium, payoff functions
â”‚   â”‚   â”œâ”€â”€ simulation/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ simulator.py           # Python-based simulator
â”‚   â”‚   â”‚   â”œâ”€â”€ trace_loader.py        # Alibaba 2018 & Google 2011 traces
â”‚   â”‚   â”‚   â””â”€â”€ execution_engine.py    # Task execution & failure handling
â”‚   â”‚   â”œâ”€â”€ baselines/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ standard_gwo.py        # Vanilla GWO (no memory)
â”‚   â”‚   â”‚   â”œâ”€â”€ fogmatch.py            # FogMatch scheduler
â”‚   â”‚   â”‚   â”œâ”€â”€ pso_scheduler.py       # PSO-based scheduler
â”‚   â”‚   â”‚   â”œâ”€â”€ mohhots.py             # Multi-objective HHO
â”‚   â”‚   â”‚   â”œâ”€â”€ first_fit.py           # Greedy first-fit heuristic
â”‚   â”‚   â”‚   â”œâ”€â”€ relief.py              # RL-based scheduler
â”‚   â”‚   â”‚   â””â”€â”€ mpso_ft.py             # Modified PSO with fault tolerance
â”‚   â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py             # TSR, energy, latency, network metrics
â”‚   â”‚   â”‚   â”œâ”€â”€ plotting.py            # Figure generation (matplotlib)
â”‚   â”‚   â”‚   â””â”€â”€ table_generator.py     # Results table generation
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config_loader.py       # YAML config parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ logging_utils.py       # Structured JSON logging
â”‚   â”‚   â”‚   â””â”€â”€ helpers.py             # Utility functions
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ cli.py                     # Main CLI entry point
â”‚   â”‚   â”œâ”€â”€ run_demo.sh                # Quick demo (small topology)
â”‚   â”‚   â”œâ”€â”€ run_full_experiments.sh    # Full experimental suite
â”‚   â”‚   â”œâ”€â”€ run_ablations.sh           # Ablation studies
â”‚   â”‚   â”œâ”€â”€ generate_plots.py          # Figure + table generation
â”‚   â”‚   â””â”€â”€ run_all.sh                 # Master script (reproducibility)
â”‚   â”‚
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_objectives.py         # Energy/reliability computation
â”‚       â”œâ”€â”€ test_constraints.py        # Feasibility checks
â”‚       â”œâ”€â”€ test_mdgwo.py              # Wolf updates, memory archive
â”‚       â”œâ”€â”€ test_game_theory.py        # Payoff, equilibrium
â”‚       â”œâ”€â”€ test_baselines.py          # Baseline algorithm correctness
â”‚       â””â”€â”€ conftest.py                # Pytest fixtures
â”‚
â”œâ”€â”€ java/
â”‚   â””â”€â”€ ifogsim-mdgwo/
â”‚       â”œâ”€â”€ pom.xml                    # Maven config
â”‚       â”œâ”€â”€ src/main/java/
â”‚       â”‚   â””â”€â”€ org/siren/
â”‚       â”‚       â”œâ”€â”€ core/
â”‚       â”‚       â”‚   â”œâ”€â”€ FogTopology.java
â”‚       â”‚       â”‚   â”œâ”€â”€ TaskExecutor.java
â”‚       â”‚       â”‚   â””â”€â”€ SystemMonitor.java
â”‚       â”‚       â”œâ”€â”€ integration/
â”‚       â”‚       â”‚   â”œâ”€â”€ MDGWOOptimizer.java
â”‚       â”‚       â”‚   â””â”€â”€ SchedulerService.java
â”‚       â”‚       â””â”€â”€ utils/
â”‚       â”‚           â””â”€â”€ Serialization.java
â”‚       â””â”€â”€ src/test/java/
â”‚           â””â”€â”€ org/siren/
â”‚               â”œâ”€â”€ SimulationTest.java
â”‚               â””â”€â”€ IntegrationTest.java
â”‚
â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ terraform/
â”‚   â”‚   â”œâ”€â”€ main.tf                    # AWS infrastructure (EC2, S3, VPC)
â”‚   â”‚   â”œâ”€â”€ variables.tf               # Input variables
â”‚   â”‚   â”œâ”€â”€ outputs.tf                 # Output values
â”‚   â”‚   â””â”€â”€ terraform.tfvars.example   # Example variable values
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile.python          # Python runtime image
â”‚   â”‚   â”œâ”€â”€ Dockerfile.java            # Java + iFogSim image
â”‚   â”‚   â””â”€â”€ docker-compose.yml         # Multi-container orchestration
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ init_instances.sh          # Instance provisioning
â”‚       â”œâ”€â”€ run_experiment.sh          # Launch experiment on EC2
â”‚       â”œâ”€â”€ collect_results.sh         # Gather S3 outputs
â”‚       â””â”€â”€ cleanup.sh                 # Tear down infrastructure
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ traces/
â”‚   â”‚   â”œâ”€â”€ alibaba_2018_sample.csv    # Alibaba cluster trace (sample)
â”‚   â”‚   â””â”€â”€ google_2011_sample.csv     # Google cluster trace (sample)
â”‚   â””â”€â”€ outputs/
â”‚       â””â”€â”€ (experiment results)
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ figures/
    â”‚   â”œâ”€â”€ energy_alibaba.pdf
    â”‚   â”œâ”€â”€ energy_google.pdf
    â”‚   â”œâ”€â”€ reliability_comparison.pdf
    â”‚   â””â”€â”€ ... (all paper figures)
    â””â”€â”€ tables/
        â”œâ”€â”€ results_summary.csv
        â”œâ”€â”€ ablation_study.csv
        â””â”€â”€ sensitivity_analysis.csv
```

## Getting Started

### Prerequisites

- Python 3.9+
- Java 11+ (for iFogSim integration)
- Docker & Docker Compose (for AWS deployment)
- Terraform 1.0+ (for AWS infrastructure)

### Installation

```bash
# Clone the repository
git clone <repo-url> && cd siren-fog-gwo

# Create a virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .
```

### Quick Start (Demo)

Run a small-scale demo to verify the installation:

```bash
cd python/scripts
bash run_demo.sh
```

This will:
1. Load a small topology (20 fog nodes, 200 tasks)
2. Run MD-GWO for 50 iterations
3. Compare against 3 baselines
4. Print results and generate `results/demo_output.json`

**Expected runtime**: ~30 seconds on a modern laptop.

### Full Experimental Suite

Reproduce all paper results:

```bash
cd python/scripts
bash run_all.sh
```

This master script will:
1. Run experiments on Alibaba 2018 trace (1000, 2000, 3000 tasks, 20-100 nodes)
2. Run experiments on Google 2011 trace (same scales)
3. Run healthcare scenario (iFogSim)
4. Generate all figures and tables
5. Output to `results/figures/` and `results/tables/`

**Expected runtime**: ~2-4 hours (parallelizable across 8+ cores).

### Configuration

All parameters are configured via YAML files in `configs/`:

- **topology.yaml**: Fog node counts, CPU/memory specs, failure rates, network latencies
- **workload.yaml**: Task arrival rates, criticality distribution, deadlines
- **algorithm.yaml**: MD-GWO population size, iterations, weights (Î²â‚, Î²â‚‚)
- **evaluation.yaml**: Metrics to track, baseline selections, plot styles

### Running Individual Experiments

```bash
# Demo with healthcare scenario
python python/scripts/cli.py --mode demo --scenario healthcare --nodes 20 --tasks 200

# Full run on Alibaba trace
python python/scripts/cli.py --mode full --trace alibaba --nodes 100 --tasks 3000 --seed 42

# Ablation study (vary population size)
python python/scripts/cli.py --mode ablation --param population --values "50,100,150,200"

# Generate plots only
python python/scripts/generate_plots.py --results-dir data/outputs
```

## Implementation Details

### 1. System Model (models/system_model.py)

**Components**:
- **Fog Layer**: $N_{\text{fog}}$ heterogeneous nodes with CPU (MIPS), memory (MB), bandwidth (Mbps)
- **Cloud Layer**: 1-2 centralized data centers with virtually unlimited resources
- **IoT Layer**: Task generators with Poisson arrival process
- **Network**: Latency $L_{xy}$, bandwidth $BW_{xy}$ for any pair $(x,y)$

**Task Model**:
- Workload $W_j$ (million instructions)
- Input/output data sizes $D_{j,\text{in}}, D_{j,\text{out}}$ (MB)
- Memory requirement $Mem_j$ (MB)
- Deadline $Deadline_j$ (seconds)
- Criticality flag $Criticality_j \in \{0,1\}$

**Reliability Model** (exponential failure):
- Node $F_i$ failure rate: $\lambda_i$ (failures/hour)
- Task success probability with replication: $P_{\text{succ}}(T_j) = 1 - \prod_{k=1}^{r_j} P_{\text{fail}}(T_j|F_{i_k})$ (Eq. 6 in paper)

**Energy Model** (DVFS-aware):
- Active power: $P(f) = \alpha f^3 + \beta f + \gamma$ (cubic frequency dependence, Eq. 4)
- Compute energy: $E_{\text{comp}} = P(f) \cdot T_{\text{exec}}$ (Eq. 5)
- Communication energy: $E_{\text{comm}} = P_{\text{tx}} \cdot T_{\text{trans}} + P_{\text{rx}} \cdot T_{\text{trans}}$ (Eq. 8)

### 2. Objectives & Constraints (models/objectives.py, models/constraints.py)

**Multi-Objective Formulation**:
```
Minimize: E_total = Î£â±¼ Î£áµ¢ xâ±¼áµ¢ (E_comp + E_comm)        (Eq. 9)
Maximize: R_system = (1/N_task) Î£â±¼ P_succ(T_j)        (Eq. 11)

Subject to:
- CPU:     Î£â±¼ xâ±¼áµ¢ Wâ±¼/Î”t â‰¤ CPU_i   âˆ€i                 (Eq. 12-14)
- Memory:  Î£â±¼ xâ±¼áµ¢ Mem_j â‰¤ MEM_i   âˆ€i
- Replication: Î£áµ¢ xâ±¼áµ¢ = r_j       âˆ€j (r_j â‰¤ r_max=3)
- Deadline: T^end_j â‰¤ Deadline_j   âˆ€j
- Reliability: P_succ(T_j) â‰¥ R_min (if Criticality_j=1)
```

**Scalarization** (weighted sum + penalty):
```
Fit(X) = Î²â‚ Â· E_total(X) - Î²â‚‚ Â· R_system(X) + P(X)    (Eq. 10)

where P(X) = Ï_cpu Â· Î£áµ¢ max(0, Î£â±¼ xâ±¼áµ¢ Wâ±¼ / CPU_i - 1)
           + Ï_mem Â· Î£áµ¢ max(0, Î£â±¼ xâ±¼áµ¢ Mem_j / MEM_i - 1)
           + Ï_dl  Â· Î£â±¼ ğ•€[T^end_j > Deadline_j]
           + Ï_rel Â· Î£â±¼ ğ•€[P_succ(T_j) < R_min]
```

Default weights: Î²â‚=0.6 (energy importance), Î²â‚‚=0.4 (reliability importance)

### 3. Game-Theoretic Engine (algorithms/game_theory.py)

**Game Structure**:
- **Players**: Fog nodes $F_i \in \mathcal{F}$
- **Strategies**: Each node's decision tuple $(x_{ji}, r_j, f_{i,t})$ for its assigned tasks
- **Payoff**: 
  ```
  U_i = Ï‰_R Â· Î£ P_succ(T_j|F_i) - Ï‰_E Â· (E_comp + E_comm)    (Eq. 7)
  ```
  where $Ï‰_R, Ï‰_E$ are importance weights

- **Equilibrium Concept**: Îµ-Nash equilibrium where $U_i(s_i^*, s_{-i}^*) â‰¥ U_i(s_i, s_{-i}^*) - Îµ$

**Implementation**:
- Payoff functions computed per wolf during fitness evaluation
- Existence & uniqueness proofs in appendix (Kakutani's fixed-point theorem)
- MDGWO search targets near-Nash configurations

### 4. Memory-Driven Grey Wolf Optimization (algorithms/mdgwo.py)

**Wolf Encoding**:
Each wolf position is a vector of triplets for $N_T$ tasks:
```
X = [(x_{1,1}, x_{1,2}, x_{1,3}), ..., (x_{N_T,1}, x_{N_T,2}, x_{N_T,3})]

where:
  x_{j,1} âˆˆ [0, N_fog+N_cloud]   â†’ node ID (discretized)
  x_{j,2} âˆˆ [1, r_max]            â†’ replication factor (discretized)
  x_{j,3} âˆˆ [f_min, f_max]        â†’ CPU frequency (quantized to L levels)
```

**Update Rule** (with memory):
```
X_k^(t+1) = (1/3)(X_Î±^t + X_Î²^t + X_Î´^t) + Î·(t)(X_{k,pbest} - X_k^t)    (Eq. 19)

where:
  X_Î±, X_Î², X_Î´ = best 3 wolves (social leaders)
  X_{k,pbest} = wolf k's historical best position (memory)
  Î·(t) = decay coefficient âˆˆ [0,1] (shifts exploration â†’ exploitation)
```

**Memory Mechanism**:
- Each wolf stores its personal best $X_{k,\text{pbest}}$ (per-wolf archive)
- Updated only if current solution improves fitness
- Enables algorithm to escape local optima and preserve good partial solutions

**Discretization** (post-update):
```
node_ID â† floor(x_{j,1}) mod (N_fog+N_cloud)
r_j â† min(round(x_{j,2}), r_max)
f_j â† f_min + round((x_{j,3} - f_min) Â· (L-1)/(f_max-f_min)) Â· Î”f
```

### 5. Baselines Implementation (baselines/)

All 7 baselines are implemented with the same fitness function and search budget (N_P=100, I=200):

1. **Standard GWO** (standard_gwo.py): Vanilla Grey Wolf Optimizer (no memory, no game theory)
2. **FogMatch** (fogmatch.py): Game-theory-based resource utilization minimization
3. **PSO** (pso_scheduler.py): Particle Swarm Optimization for energy + execution time
4. **MoHHOTS** (mohhots.py): Multi-objective Harris Hawk Optimizer (delay + energy)
5. **First-Fit (FF)** (first_fit.py): Greedy heuristic (max success probability per task)
6. **Relief** (relief.py): RL-based with primary-backup replication
7. **MPSO-FT** (mpso_ft.py): Modified PSO with reactive fault tolerance

All baselines are adapted to use the unified fitness function (Eq. 10) for fair comparison.

### 6. Evaluation & Metrics (evaluation/)

**Metrics**:
- **Task Success Rate (TSR)**: % of tasks completed within deadline despite failures
- **Total Energy**: Sum of compute + communication + idle energy (kWh or Joules)
- **Average Response Time**: Mean task completion time (seconds)
- **Network Usage**: Total data transmitted (GB)
- **Convergence**: Fitness improvement per iteration
- **Diversity**: Entropy of replication distribution

**Figures** (matplotlib):
- Energy vs. task/node scaling (Alibaba & Google traces)
- Reliability comparison (healthcare scenarios)
- Response time distributions
- Pareto front (energy vs. reliability trade-off)

**Tables** (CSV + LaTeX):
- Algorithm comparison (TSR, energy, latency, network)
- Sensitivity analysis (population, iterations, weights)
- Scalability metrics (compute time, memory usage)

### 7. Python CLI & Scripts (python/scripts/)

```bash
# Main entry point
python cli.py \
  --mode {demo|full|ablation} \
  --scenario {healthcare|alibaba|google} \
  --nodes 20 \
  --tasks 1000 \
  --seed 42 \
  --config configs/algorithm.yaml \
  --output results/

# Run small demo
bash run_demo.sh

# Full reproduction
bash run_all.sh

# Generate plots from existing results
python generate_plots.py --results-dir data/outputs --format pdf

# Run specific ablation (vary population)
python cli.py --mode ablation --param population --values "50,100,150,200"
```

## AWS Deployment

### Infrastructure Setup (Terraform)

```bash
cd aws/terraform

# Configure AWS credentials
export AWS_ACCESS_KEY_ID=<your-key>
export AWS_SECRET_ACCESS_KEY=<your-secret>
export AWS_REGION=us-east-1

# Initialize and deploy
terraform init
terraform plan -var-file=terraform.tfvars
terraform apply -auto-approve

# Retrieve instance IPs
terraform output instance_ips
```

**Terraform Resources**:
- 15 EC2 instances (t4g.small, t4g.medium, t4g.large, t3a.xlarge, t3a.2xlarge)
- VPC with public/private subnets
- S3 bucket for results storage
- IAM roles for EC2 â†’ S3 access
- Security groups (SSH, HTTPS)

### Docker Images

```bash
# Build Python image
docker build -f aws/docker/Dockerfile.python -t siren:python .

# Build Java image
docker build -f aws/docker/Dockerfile.java -t siren:java .

# Push to ECR (optional)
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account>.dkr.ecr.us-east-1.amazonaws.com
docker tag siren:python <account>.dkr.ecr.us-east-1.amazonaws.com/siren:python
docker push <account>.dkr.ecr.us-east-1.amazonaws.com/siren:python
```

### Running Experiments on AWS

```bash
cd aws/scripts

# 1. Provision instances and install dependencies
bash init_instances.sh --instance-ids i-xxx,i-yyy

# 2. Launch experiment on all instances
bash run_experiment.sh --config ../terraform/terraform.tfvars --workload alibaba --nodes 100 --tasks 3000

# 3. Collect results from S3
bash collect_results.sh --bucket siren-results-bucket --local-dir /tmp/results

# 4. Clean up
bash cleanup.sh
```

### Cost Estimates

On AWS (us-east-1, on-demand):
- **Demo (20 nodes, 200 tasks)**: ~$0.50 (5 min)
- **Full suite (100 nodes, 3000 tasks, 10 runs)**: ~$50-100 (6 hours)

Use spot instances for 70% cost reduction (with interruption risk).

## Testing

Run all tests:

```bash
cd python
pytest tests/ -v --cov=fog_gwo_scheduler --cov-report=html
```

**Test Coverage**:
- **test_objectives.py**: Energy/reliability computation (10+ tests)
- **test_constraints.py**: Feasibility checking, penalty function (8+ tests)
- **test_mdgwo.py**: Wolf initialization, updates, memory archive, discretization (15+ tests)
- **test_game_theory.py**: Payoff computation, best-response dynamics (10+ tests)
- **test_baselines.py**: All 7 baselines run and converge (7 tests)

**Unit Tests** verify:
- Fitness function correctness against ground truth
- Constraint violations properly penalized
- Memory archive updates reflect best solutions
- Discretization preserves solution validity
- All baselines produce feasible schedules

## Reproducibility

### Fixed Seeds

All random elements use fixed seeds for reproducibility:

```python
# Python
np.random.seed(SEED)
random.seed(SEED)
tf.random.set_seed(SEED)  # if using TensorFlow

# Java
java.util.Random rng = new java.util.Random(SEED);
```

Default: `SEED = 42`

### Dependency Pinning

All versions are pinned in `requirements.txt`:

```
numpy==1.24.3
scipy==1.11.0
matplotlib==3.7.1
pandas==2.0.3
pyyaml==6.0
pytest==7.4.0
pytest-cov==4.1.0
...
```

### Configuration Locking

Experiment configs are saved with results:

```
data/outputs/
â”œâ”€â”€ experiment_<timestamp>.log
â”œâ”€â”€ config_<timestamp>.yaml
â”œâ”€â”€ results_<timestamp>.csv
â””â”€â”€ ...
```

### Validation

To verify reproducibility:

```bash
# Run same experiment twice with identical config
python cli.py --mode full --seed 42 --config configs/algorithm.yaml > run1.log
python cli.py --mode full --seed 42 --config configs/algorithm.yaml > run2.log

# Compare outputs (should be bitwise identical)
diff <(grep "TSR\|Energy" run1.log) <(grep "TSR\|Energy" run2.log)
```

## Performance & Scalability

### Computational Complexity

For one optimization round:

$$T_{\text{round}} = \mathcal{O}(I \cdot N_P \cdot (N_T \bar{r} + N_F))$$

where:
- $I$ = MDGWO iterations (200)
- $N_P$ = population size (100)
- $N_T$ = number of tasks (1000â€“3000)
- $\bar{r}$ = avg replication factor (~1.2)
- $N_F$ = number of fog nodes (20â€“100)

**Typical runtime**:
- 20 nodes, 200 tasks, 200 iterations: ~10 seconds
- 100 nodes, 3000 tasks, 200 iterations: ~5 minutes

**Space Complexity**: $\mathcal{O}(N_P \cdot N_T \bar{r})$ â‰ˆ 12 MB (for N_P=100, N_T=3000, rÌ„=1.2)

### Parallelization

- **Fitness evaluations**: Parallelize across wolves (100Ã— speedup on 8+ cores)
- **Baseline runs**: Parallelize across baselines (7Ã— speedup)
- **Traces**: Process independent traces in parallel (3Ã— speedup)

With parallelization, full suite runtime: **~30 minutes** on 16-core machine.

<!-- ## Citation

If you use SIREN in your research, please cite:

```bibtex
@article{younesi2025siren,
  title={{SIREN}: Multi-Objective Game-Theoretic Scheduler based on Memory-Driven Grey Wolf Optimization in Fog-Cloud Computing},
  author={Younesi, Abolfazl and Ansari, Mohsen and Ejlali, Alireza and Fazli, Mohammad Amin and Shafique, Muhammad and Henkel, J\"org},
  journal={IEEE Internet of Things Journal},
  year={2025}
}
``` -->

## License

This project is licensed under the Apache License 2.0. See [LICENSE](LICENSE) for details.

## Support & Contribution

For issues, questions, or contributions, please open an issue or pull request on GitHub.

**Maintainers**:
- Abolfazl Younesi (University of Innsbruck)
- Mohsen Ansari (Sharif University of Technology)

---

**Last Updated**: January 2025
